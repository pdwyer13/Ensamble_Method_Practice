{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW7_Dwyer_Patrick.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UDtpJLrCXdj-",
        "TC9xxX-MaJiJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEBNn7WNVVH9"
      },
      "source": [
        "# Homework 7 (30 marks)\n",
        "Create a copy of the notebook to start answering the questions. Name your notebook in the format HW7_lastname_firstname.ipynb to facilitate the grading process.\n",
        "\n",
        "Answer all the questions, test your code to ensure there are no errors and the results are as expected. Once you have answered all the questions, save the final copy, then go to File-> click on Download.ipynb. Once the local copy has been downloaded, submit your file on Blackboard under the corresponding assignment section. Also provide us a link to your notebook during submission.\n",
        "\n",
        "NOTE: Please give the TAs the permission to access your notebooks through the links you have provided during submission.\n",
        "\n",
        "The due date of this homework is 04/23/2021 (Friday).\n",
        "\n",
        "Please ensure you follow all the steps mentioned in the homework.\n",
        "\n",
        "You can submit your solutions any number of times until the deadline.\n",
        "\n",
        "The datasets used in this homework can be found in the google drive link below -\n",
        "\n",
        "https://drive.google.com/drive/folders/1NxCh4X7u7wVo5aHojxjLNs9wC7B7zJhb?usp=sharing\n",
        "\n",
        "Follow the necessary steps to import data to test your code. You can use any method to read your data in the notebook. We will not be grading the methods you use. We will only grade the code from the point where you read the dataset into a pandas dataframe - (pd.read_csv('file_name'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNkmD9GdVx37"
      },
      "source": [
        "Import all the libraries you require in the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O38dWgFrTt9g"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Enter your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HggTkCZoWOSE"
      },
      "source": [
        "## Implement the Ensemble methods learnt in class and compare their accuarcies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-eAjVVDV_Nm"
      },
      "source": [
        "The dataset you are going to be using for homework is the **Wisconsin Breast Cancer dataset (cancer.csv)**\n",
        "\n",
        "The dataset contains a total number of 10 features labeled in either benign or malignant classes. The features have 699 instances out of which 16 feature values are missing. The dataset only contains numeric values.\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1. Sample code number: id number\n",
        "2. Clump Thickness: 1 - 10\n",
        "3. Uniformity of Cell Size: 1 - 10\n",
        "4. Uniformity of Cell Shape: 1 - 10\n",
        "5. Marginal Adhesion: 1 - 10\n",
        "6. Single Epithelial Cell Size: 1 - 10\n",
        "7. Bare Nuclei: 1 - 10\n",
        "8. Bland Chromatin: 1 - 10\n",
        "9. Normal Nucleoli: 1 - 10\n",
        "10. Mitoses: 1 - 10\n",
        "11. Class: (2 for benign, 4 for malignant) (**target variable**)\n",
        "\n",
        "For more information: https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3iLZY-gXhVH"
      },
      "source": [
        "### 1. Read the dataset into variable called '**data**' (1 mark)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2II5L3AXn2A"
      },
      "source": [
        "pd.set_option('display.max_columns', 100)\n",
        "# Enter your code here\n",
        "data = pd.read_csv(\"cancer.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DvQpJcMXRd0"
      },
      "source": [
        "### **Preprocessing**: Data needs to be preprocessed before implementing ensemble methods. It is done for you here. \n",
        "### Run the below code first and then answer the questions from 2 - 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDtpJLrCXdj-"
      },
      "source": [
        "#### Deleting unnecessary columns: The column \"Sample code number\" is just an indicator and it's of no use in the modeling. So, let's drop it:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bbOI9AYTziJ"
      },
      "source": [
        "data.drop(['Sample Code Number'],axis = 1, inplace = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaUqMhEPYqSF"
      },
      "source": [
        "#### Handling missing values : \n",
        "As mentioned earlier, the dataset contains missing values. The column named \"Bland Chromatin\" contains them. The missing values are represneted as \"?\". \n",
        "\n",
        "Replace those \"?\"s with 0's and impute them with Mean Imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHu_DIDcZs_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde9dc86-f134-4b8f-b4be-6e0768ab9c63"
      },
      "source": [
        "data['Bland Chromatin']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1      10\n",
              "2       2\n",
              "3       4\n",
              "4       1\n",
              "       ..\n",
              "694     2\n",
              "695     1\n",
              "696     3\n",
              "697     4\n",
              "698     5\n",
              "Name: Bland Chromatin, Length: 699, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_5GSsVjU930"
      },
      "source": [
        "data.replace('?',0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV3PVQB0U_mF"
      },
      "source": [
        "# Convert the DataFrame object into NumPy array otherwise you will not be able to impute\n",
        "values = data.values\n",
        "# Now impute it\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputedData = imputer.fit_transform(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC9xxX-MaJiJ"
      },
      "source": [
        "#### Normalizing the data:\n",
        "Ranges of the features of the dataset are not the same. This may cause a problem. A small change in a feature might not affect the other. To address this problem, normalize the ranges of the features to a uniform range, in this case, 0 - 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VomHojxET85c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491fcc82-bcdb-493f-fecf-b8fd48e2ea3d"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "normalizedData = scaler.fit_transform(imputedData)\n",
        "cols = ['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bland Chromatin', 'Bare Nuclei', 'Normal Nucleoli', 'Mitosis','Class']\n",
        "normalizedData = pd.DataFrame(normalizedData, columns=cols)\n",
        "print(normalizedData.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
            "0         0.444444                 0.000000                  0.000000   \n",
            "1         0.444444                 0.333333                  0.333333   \n",
            "2         0.222222                 0.000000                  0.000000   \n",
            "3         0.555556                 0.777778                  0.777778   \n",
            "4         0.333333                 0.000000                  0.000000   \n",
            "\n",
            "   Marginal Adhesion  Single Epithelial Cell Size  Bland Chromatin  \\\n",
            "0           0.000000                     0.111111              0.1   \n",
            "1           0.444444                     0.666667              1.0   \n",
            "2           0.000000                     0.111111              0.2   \n",
            "3           0.000000                     0.222222              0.4   \n",
            "4           0.222222                     0.111111              0.1   \n",
            "\n",
            "   Bare Nuclei  Normal Nucleoli  Mitosis  Class  \n",
            "0     0.222222         0.000000      0.0    0.0  \n",
            "1     0.222222         0.111111      0.0    0.0  \n",
            "2     0.222222         0.000000      0.0    0.0  \n",
            "3     0.222222         0.666667      0.0    0.0  \n",
            "4     0.222222         0.000000      0.0    0.0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb2YjZckaZ2-"
      },
      "source": [
        "### Data preprocessing is done and now you will answer the below questions using the **normalizedData**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq2ChemrbDz2"
      },
      "source": [
        "### 2. Split the data into test and training data with test size - 30%. Compute the baseline classification accuracy for X_train. (3 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOshE9K_UA5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd9611d-5d28-4ec8-ea89-8eccc0d5f64a"
      },
      "source": [
        "# Enter your code here\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X = normalizedData[cols[0:9]]\n",
        "y = normalizedData[\"Class\"]\n",
        "\n",
        "print(normalizedData.shape)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    stratify=y,random_state=42\n",
        "                                                    )\n",
        "dummy_classifier = DummyClassifier(strategy='most_frequent')\n",
        "dummy_classifier.fit(X_train,y_train)\n",
        "baseline_acc = dummy_classifier.score(X_train,y_train)\n",
        "\n",
        "### For verifying answer:\n",
        "print(\"Baseline Accuracy = \", baseline_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(699, 10)\n",
            "(699, 9)\n",
            "(699,)\n",
            "Baseline Accuracy =  0.65439672801636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3RUF9RvgA-N"
      },
      "source": [
        "### 3.  Bagging : Build a generic Bagging ensemble and print the accuracy (4 marks)\n",
        "---\n",
        "\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "Base estimator = DecisionTreeClassifier\n",
        "\n",
        "n_estimators = 10\n",
        "\n",
        "random_state = 42\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C78-znrIUDcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f7f91d-3929-47c2-dce6-345e8c027d50"
      },
      "source": [
        "# Generic Bagging model\n",
        "# Enter your code here\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "base_est = DecisionTreeClassifier()\n",
        "model_bag = BaggingClassifier(base_est,random_state = 42,n_estimators=10)\n",
        "model_bag.fit(X_train, y_train)\n",
        "pred_bagging = model_bag.predict(X_test)\n",
        "acc_b = accuracy_score(y_test, pred_bagging)\n",
        "\n",
        "print(' Accuracy = ', acc_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy =  0.9571428571428572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlupszlqg6El"
      },
      "source": [
        "### 4. RandomForest : (7 marks)\n",
        "#### a) Build a Random Forest model and print the accuracy (4 marks)\n",
        "---\n",
        "\n",
        "Constructor arguments: \n",
        "\n",
        "\n",
        "n_estimators = 100, max_features = 7 and random_state = 42 \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiVgGFq1UH7Q"
      },
      "source": [
        "def print_recall_scores(ensemble, feats, true_labels):\n",
        "    '''\n",
        "    Prints the recall scores for base estimators in a sklearn ensemble model.\n",
        "    '''\n",
        "    scores = []\n",
        "    for model_idx, model in enumerate(ensemble.estimators_):\n",
        "        if model_idx == 0:\n",
        "            print('='*40)\n",
        "        preds = model.predict(feats)\n",
        "        scores.append(recall_score(true_labels, preds))\n",
        "        model_recall = np.round(recall_score(true_labels, preds), 5)\n",
        "        print(f'Recall for Base Model {model_idx+1}:\\t', model_recall)\n",
        "        if model_idx < (len(ensemble.estimators_) - 1):\n",
        "            print('-'*40)\n",
        "        else:\n",
        "            print('='*40)\n",
        "    ensemble_preds = ensemble.predict(feats)\n",
        "    print(\"Mean Recall Score:\\t\\t\", np.round(np.array(scores).mean(), 5))\n",
        "    print(\"Std Deviation:\\t\\t\\t\", np.round(np.array(scores).std(), 5))\n",
        "    print(\"Range:\\t\\t\\t\\t\", np.round(np.array(scores).ptp(), 5))\n",
        "    print(f'Overall Recall for model:\\t {np.round(recall_score(y_test, ensemble_preds), 5)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TagawD02hKlF",
        "outputId": "2918ca65-0e49-43b6-d27a-d1dd95ff50c8"
      },
      "source": [
        "# Random Forest model\n",
        "# Enter your code here\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    accuracy_score)\n",
        "model_rf = RandomForestClassifier(n_estimators=100, max_features=7, random_state=42)\n",
        "model_rf.fit(X_train, y_train)\n",
        "predict_rf = model_rf.predict(X_test)\n",
        "recall_rf = recall_score(y_test, predict_rf)\n",
        "precision_rf = precision_score(y_test, predict_rf)\n",
        "\n",
        "print_recall_scores(model_bag, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Recall for Base Model 1:\t 0.86111\n",
            "----------------------------------------\n",
            "Recall for Base Model 2:\t 0.91667\n",
            "----------------------------------------\n",
            "Recall for Base Model 3:\t 0.91667\n",
            "----------------------------------------\n",
            "Recall for Base Model 4:\t 0.93056\n",
            "----------------------------------------\n",
            "Recall for Base Model 5:\t 0.90278\n",
            "----------------------------------------\n",
            "Recall for Base Model 6:\t 0.91667\n",
            "----------------------------------------\n",
            "Recall for Base Model 7:\t 0.93056\n",
            "----------------------------------------\n",
            "Recall for Base Model 8:\t 0.91667\n",
            "----------------------------------------\n",
            "Recall for Base Model 9:\t 0.91667\n",
            "----------------------------------------\n",
            "Recall for Base Model 10:\t 0.88889\n",
            "========================================\n",
            "Mean Recall Score:\t\t 0.90972\n",
            "Std Deviation:\t\t\t 0.01989\n",
            "Range:\t\t\t\t 0.06944\n",
            "Overall Recall for model:\t 0.94444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48iH9eV8xkbE"
      },
      "source": [
        "####  b) Calculate the top 3 important features for the above **RandomForest** model and print them (3 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M469DqsQxlFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75fb1ba5-0f8a-4ee6-93d2-313e9cc62431"
      },
      "source": [
        "# Top 3 features for RandomForest\n",
        "# Enter your code here\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = X_train.columns\n",
        "df = pd.DataFrame({'features': features, 'importance': feature_importances})\n",
        "df = df.sort_values(by=[\"importance\"],ascending=False)\n",
        "print(df[0:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   features  importance\n",
            "1   Uniformity of Cell Size    0.503253\n",
            "5           Bland Chromatin    0.229520\n",
            "2  Uniformity of Cell Shape    0.095969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnrkSasYh6gF"
      },
      "source": [
        "### 5. Boosting: (7 marks)\n",
        "#### a) Build an AdaBoost model with training data and print the accuracy (4 marks)\n",
        "---\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "Base estimator = DecisionTreeClassifier, max_depth = 4\n",
        "\n",
        "n_estimators = 200\n",
        "\n",
        "random_state = 42\n",
        "\n",
        "learning_rate = 0.05\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQIzaUjWUHv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db5b679-1d55-4e08-95cd-9bd0696256b8"
      },
      "source": [
        "# AdaBoost Classification\n",
        "# Enter your code here\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "base_est = DecisionTreeClassifier (max_depth=4)\n",
        "ada = AdaBoostClassifier(base_est, n_estimators=200, random_state=42, learning_rate=.05)\n",
        "ada.fit(X_train, y_train)\n",
        "result = round(recall_score(y_test, ada.predict(X_test)),4)\n",
        "\n",
        "print('MODEL 1 Recall:\\t {}'.format(result))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL 1 Recall:\t 0.9306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usBQDazfw2L1"
      },
      "source": [
        "#### b) Calculate the top 3 important features for the above **AdaBoost** model and print them (3 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbEUjwQRw3rW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa03e24-6618-44fb-8b89-406023c54574"
      },
      "source": [
        "# Top 3 features for AdaBoost\n",
        "# Enter your code here\n",
        "feature_importances = ada.feature_importances_\n",
        "features = X_train.columns\n",
        "df = pd.DataFrame({'features': features, 'importance': feature_importances})\n",
        "df = df.sort_values(by=[\"importance\"],ascending=False)\n",
        "print(df[0:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  features  importance\n",
            "0          Clump Thickness    0.323357\n",
            "1  Uniformity of Cell Size    0.183736\n",
            "7          Normal Nucleoli    0.138899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMpdvP7ZjAOt"
      },
      "source": [
        "### 6. Voting : Using a voting classifier, build an ensemble of RandomForestClassifier, DecisionTreeClassifier, Support Vector Machine and Logistic Regression. (7 marks)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Use max_depth = 4, n_estimators = 200, voting = soft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M3ZIcrqUKjK"
      },
      "source": [
        "# Voting Ensemble for Classification\n",
        "# Enter your code here\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn import model_selection\n",
        "\n",
        "kfold = model_selection.KFold()\n",
        "dectree_v = DecisionTreeClassifier(max_depth=4)\n",
        "randomforest_v = RandomForestClassifier(n_estimators=200)\n",
        "supportvector_v = svm.SVC(probability=True)\n",
        "log_v = LogisticRegression()\n",
        "ensamble = VotingClassifier(estimators=[('dt', dectree_v), ('randomforest', randomforest_v), ('svc', supportvector_v),('log_v',log_v)],voting='soft')\n",
        "\n",
        "dectree_v = dectree_v.fit(X_train, y_train)\n",
        "randomforest_v = randomforest_v.fit(X_train, y_train)\n",
        "supportvector_v = supportvector_v.fit(X_train, y_train)\n",
        "log_v = log_v.fit(X_train, y_train)\n",
        "ensamble = vc_v.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj2CVbBYVTun"
      },
      "source": [
        "### 7. Mention the best model among the above 4 models and its accuracy (1 mark)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj09m4z_lXNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0564fd53-61e3-4aa7-d254-a491c2dcdbcf"
      },
      "source": [
        "# Write your answer here\n",
        "\n",
        "dtres = model_selection.cross_val_score(dectree_v, X_test, y_test,cv=kfold)\n",
        "randomforestres = model_selection.cross_val_score(randomforest_v, X_test, y_test,cv=kfold)\n",
        "supportres = model_selection.cross_val_score(supportvector_v, X_test, y_test,cv=kfold)\n",
        "logres = model_selection.cross_val_score(log_v, X_test, y_test,cv=kfold)\n",
        "print(dtres.mean(),randomforestres.mean(),supportres.mean(),logres.mean())\n",
        "print(\"The best model is Support Vector with an estimated accuracy of\",supportres.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9142857142857143 0.9428571428571428 0.9571428571428571 0.9333333333333333\n",
            "The best model is Support Vector with an estimated accuracy of 0.9571428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}